---
published: false
title: Lecture 11. CNNs in Practice
category: [CS231n]
use_math: true
---

> 해당 포스트는 송교석 님의 유튜브 강의를 정리한 내용입니다. 강의 영상은 [여기](https://youtube.com/playlist?list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5)에서 보실 수 있습니다.

이번 포스트에서는 CNN 을 현실에서 어떻게 사용하는지에 대해서 깊이 있게 알아보도록 하겠습니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-001.png)

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-010.png)

## Making the most of your data

### Data Augmentation

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-012.png)

CNN 에서는 Image 와 Label 을 CNN 에 feed 해주고, 이로부터 loss 를 계산해 줌으로써 오차를 줄여나가는 최적화 과정을 통해서 Classificaiton 을 하는 식으로 진행했었습니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-013.png)

그런데, Data Augmentation 에서는 CNN 에 Image 를 feed 해주기 전에 데이터를 변형해주는 한 가지 과정을 더 거치게 됩니다.

그래서 어떠한 변형 방법을 이용할 것인지 정하는 것이 다양한 Augmentation 의 방법이 되겠습니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-014.png)

Data Augmentation 이라는 것은 label 은 변경하지 않고 pixel 의 내용을 바꾸는 것입니다. 이렇게 변경된 데이터를 통해서 학습하고 실제로 매우 폭 넓게 이용되고 있습니다.

#### 1. Horizontal flips

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-015.png)

첫 번째로 가장 간단한 방법은 `Horizontal flip` 즉 좌우반전 입니다. 거울에 비춘것 처럼 변형이 되기 때문에 Mirror Image 라고도 합니다.

#### 2. Random crops/scales

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-018.png)

두 번째로, Random 한 crop 과 scale 이 되겠습니다. 이 방법은 먼저 위 그림처럼 랜덤하게 이미지를 잘라주고, scale 도 다양하게 합니다. 이렇게 random cropped/scaled Image 를 학습 시켜줍니다.

예를 들어 ResNet 에서는 [256, 480] 의 범위에서 랜덤하게 수를 선택해주고 training 이미지를 resize 해줍니다. 이때 짧은 부분이 L 이 되도록 하고, 이후 [224 x 224]의 패치를 랜덤하게 샘플링하여 추출해 줍니다. 이렇게 해서 나온 [224 x 224]의 이미지는 ResNet 에 들어가는 이미지의 크기가 되겠습니다.

이처럼 Augmentation 을 이용하면 Training 시에 이미지 전체가 아니라 Crop 된 패치에 대한 학습이 이루어지기 때문에 테스트시에도 이미지 전체가 아닌 정해진 수의 crop 을 이용해서 테스트를 진행하게 됩니다. 즉, 정해진 수의 crop 을 통해 평균내는 작업을 테스트시에 하게 되는 것 입니다.

예를 들어, 우측 이미지에서처럼 서로 다른 5개의 crop 을 가지고 있을 때, 이들을 horizental flip 을 하게 된다고 하면 2 x 5 의 총 10개의 crop 을 얻을 수 있는데, 이들을 평균내주는 작업을 하게 되다는 것 입니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-019.png)

다시 ResNet 의 예를 들면, ResNet 에서는 한 걸음 더 나아가서 이미지 resizing 을 {224, 256, 384, 480, 640}의 다섯 가지로 분류하고 각각의 크기에 대해서 [224 x 244] 의 Crop 을 10개를 사용한다고 합니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-021.png)

세 번째 방법으로는, Color jitter 입니다. 제일 간단한 방법은 contrast 를 위와 같이 jittering 하여 변경하는 것입니다.

이보다는 다소 복잡 하지만, 많은 경우에 사용되는 방법은 Image 의 [R, G, B] 3개의 채널에 대해서 PCA(Principal component analysis; 주성분 분석)를 이용하는 것 입니다. 

> PCA 를 굳이 이용하는 이유
> 직관적으로 볼 때, 이미지의 주성분을 뽑아냄으로써 이미지의 핵심을 잃지 않으면서도 이미지의 개수를 늘려줄 수 있기 떄문

이를 통해, 각각의 채널에 대해서 한 개씩의 principal component direction 을 얻게 됩니다. 이를 따라서 color 의 offset 을 sampling 해준 다음, 이 offset 을 image 모든 픽셀에 더해준다는 것입니다. 이외에도 더 다양한 방법들이 있습니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-022.png)

경우에 따라서 창의적인 augmentation 을 수행할 수 있다는 것으로, translation(shift), rotation, stretching, shearing, lens distortions 등 적용해야 하는 데이터 셋의 종류에 따라서 다르게 적용하여 더 좋은 효과를 거둘 수 있습니다.

그래서 나의 데이터 셋에 어떤 invariance 가 필요한지를 잘 파악한 다음에 창의적인 방법을 적용해 볼 수 있습니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-023.png)

Augmentation 을 일반적인 theme 으로 생각한다면, 다음과 같이 볼 수 있습니다.

training 과정은 랜덤한 노이즈를 더해주는 과정이 될 것이고, testing 은 노이즈를 average out(평균화)하는 과정이라고 생각할 수 있습니다. 이렇게 하면 앞에서 보았던 Dropout, DropConnect 또한 넓은 의미에서 Data Augmentation 이라고 볼 수 있습니다.

마찬가지로, Batch Normalization 이나 Model ensembles 의 경우도 이와 유사한 효과를 거두고 있다고 생각할 수 있습니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-024.png)

정리하자면, Data Augmentation 이라는 것은 매우 구현하는 것이 간단하기 떄문에 사용을 권장한다는 것이고, 특히 데이터 셋의 크기가 작은 경우 유용할 것이며, training 시에는 노이즈를 더해주고 testing 시에는 노이즈를 average out 해주는 그런 framework 이라고 생각할 수 있습니다.

### Transfer learning

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-025.png)

다음으로 Transfer learning 에 대해서 살펴보겠습니다.

CNN 을 학습시키거나 사용하려면, 굉장히 많은 데이터를 가지고 있어야만한다는 것이 어쩌면 잘못된 믿음일 수 있다는 것에서 출발합니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-027.png)

CNN 으로 Transfer learning 을 하는 것을 살펴보게 되면, 우선 위 모델을 ImageNet 에 training 시킵니다.

ImageNet 에 Training 시킨다는 것은 우리가 직접 처음부터 할 수도 있고, 아니면 미리 학습된 model 을 다운로드 받아서 구현할 수도 있습니다.

당연히, 이미 학습된 모델을 다운받아서 하는 것이 훨씬 더 효율적입니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-028.png)

그런데 이때, 가지고 있는 데이터셋이 너무 작은 경우 FC-1000 과 softmax 레이어만을 남겨놓고 앞단의 모든 부분을 freeze 해줍니다. 즉, `freeze these` 에 해당하는 부분은 더 이상 변하지 않게 됩니다. 그렇기 떄문에 ImageNet 과 같은 곳에서 학습해놓은 freeze 부분은 **feature etractor** 처럼 특징을 추출해주는 역할을 한다고 생각할 수 있습니다.

이렇게 하여 빨간 박스 부분의 레이어만 가지고 있는 데이터 셋을 이용하여 학습을 시키게 됩니다.

다른 관점에서 보게 되면, freeze 되어 있는 부분은 가중치 집합, 체크포인트 같은 것으로 hdd 저장해두는 것이고 아래 빨간 박스부분은 학습시켜야 하기 때문에 memory 에 올라와서 동작한다고 생각할 수 있습니다.

![p1](/images/cs231n/slides/lecture11/winter1516_lecture11-030.png)

데이터가 작은 경우는 앞에서와 같이 진행이 되는데, 데이터셋의 크기가 아주 크지는 않지만 학습을 못 시킬 정도로 너무 작지도 않는 경우는 **finetuning** 을 해주게 됩니다.

데이터가 정말 많은 경우라면 1번과 같이 학습을 전체 레이어에 대해서 자체적으로 진행할 수 있고, 데이터가 거의 없는 경우라면 2번과 같이 말단 부분만 학습시키며, 데이터가 더 많은 경우라면 점점 더 위쪽의 레이어까지 학습을 시켜줍니다.

그래서 freeze 하는 영역을 적절하게 데이터의 크기에 따라 선택하고 training 을 시키는 부분도 이에 따라 선택하면 되는 것입니다.

> finetuning 을 하는 말단의 레이어의 경우는 learning rate 을 원래의 lr 의 1/10 정도를 사용하고, 중간의 레이어의 경우는 1/100 정도를 사용하는 것이 좋습니다. 그 위의 레이어들은 freeze 했기 때문에 lr 을 0으로 설정해주면 됩니다.

지금까지 transfer learning 을 하는 방법에 대해 알아보았습니다.

이렇게 transfer learning 을 하는 것이 처음부터 학습시키는 것 보다 일반적으로 성능이 잘 나오는 이유는 무엇일까요?

ImageNet에 있는 pretrained 모델을 가져와서 사용한다고 했는데, 그렇게 되면 ImageNet에 있는 Class 와 전혀 무관한 이미지에 대해서도 처음부터 학습시키는 것보다 더 좋은 성능이 나온다고 하는게 좀 이상하게 느껴질 수 있습니다. 

pretrained Image(여기에서는 ImageNet)와 매우 유사한 이미지들을 Classify 하는 경우라면, 말단 부분만을 학습시켜도 나름대로 좋을 성과를 얻을 수 있는 것이고, 만약에 pretrained Image 와 전혀 관련이 없는 (ImageNet의 경우 MRI, CT 같은 의료데이터) 이미지를 Classify 하는 경우라면 train 하는 자체 데이터를 상당부분 상위 레이어까지 늘려야 된다고 생각할 수 있습니다.

이렇게 되면 상위단에 전혀 관계없는 이미지를 학습시켰다고 해서 어떻게 MRI 같은 이미지 데이터에 대한 Classify 성능이 좋아지겠는가라는 의문에 도달하게 됩니다.





> principal component direction 이란?
> color 가 변화해 나가는 방향성을 파악하게 하는 것 


## All aobut convolutions
### How to arrange them
### How to compute them fast
## Implmentation details
### GPU/CPU, bottlenecks, distributed trainingb