---
published: true
title: Lecture 9. Understanding and Visualizing Convolutional Neural Networks
category: [CS231n]
use_math: true
---

> 해당 포스트는 송교석 님의 유튜브 강의를 정리한 내용입니다. 강의 영상은 [여기](https://youtube.com/playlist?list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5)에서 보실 수 있습니다.

이번 포스트에서는 Convolutional Neural Network 를 Visualize 하는 것을 공부해보겠습니다.

`CNN`이 훌륭한 성능을 보인다는 것은 여러측면에서 살펴본 바가 있습니다만, 어떻게 그런 성능을 내는 것인지 HOW 에 대한 설명이 더 필요합니다.

그래서 이를 시각화하여 들여다보겠습니다.

## Visualizations
![p6](/images/cs231n/slides/lecture9/winter1516_lecture9-06.png)

이번 포스트에서 위와 같은 여러가지 시각화 주제에 대해서 알아볼 것인데, 우선 `CNN`이 무엇을 하는지 이해하는 가장 간단한 방법은, `CNN`의 raw activation 을 보는 것일 겁니다. 

### Visualize Patches
![p7](/images/cs231n/slides/lecture9/winter1516_lecture9-07.png)

위 이미지는 하나의 neuron 을 activation 하는 부분이 어떤 부분인가를 시각화 하서 보여주는 것입니다.

예를 들어 pool5 Layer 에서 임의의 neuron 을 취한다음에 여러 이미지들을 이 Conv. Net 에 돌려줍니다. 그렇게 하면서 이 pool5 Layer 에서 추출한 임의의 neuron 을 가장 excite 시키는 것이 어떤 이미지인지를 살펴본 것 입니다.

이미지들의 배열에서 각 행이 neuron 을 의미한다고 보면 됩니다. 첫번째행의 경우 사람에게 반응한 것이라고 보면 됩니다.

이처럼 neuron 을 가장 activation 하는 부분이 어떤 부분인지를 시각화 하는 방법이 있습니다.

### Visualize Weights 
![p7](/images/cs231n/slides/lecture9/winter1516_lecture9-08.png)

두 번째 방법은 filter 즉, kernel 을 visualize 하는 방법입니다. 

이렇게 얻은 이미지는 마치 `gabor filter` 같이 생겼습니다. `gabor filter`는 특정 방향성에 대한 외곽선을 검출하는 것으로 texture 분석에 많이 사용됩니다. 

예를 들어 conv1 의 filter 들을 시각화하게 되면 `gabor filter` 처럼 생긴 이미지를 얻게 됩니다.

그런데, 첫 번째 CONV. Layer 에 있는 필터들만 이미지에 직접 작용하게 됩니다.

그렇기 때문에, 첫 번째 레이어의 필터들만 해석이 가능하다라는 것이 되겠습니다.

![p9](/images/cs231n/slides/lecture9/winter1516_lecture9-09.png)

그 다음의 레이어들의 weight 들은 위 그림 처럼 시각화할 수는 있지만, 이 weight 들을 raw 이미지에 대한 것이 아니라, 전 단계 Layer 의 activation 에 대한 visualize 이기 때문에 해석이 용이하지 않습니다.

그래서 의미가 그렇게 크지 않은 단점이 있습니다. 위 그림에서 괄호 `()` 안의 것들이 하나의 필터에 대응하는 것이라고 보면 됩니다.

![p9](/images/cs231n/slides/lecture9/winter1516_lecture9-10.png)

사실 이런 `gabor filter` 같은 형태의 visualize 를 보면 굉장히 있어보이긴 합니다만, DeepLearning 의 CNN 에서만 만들 수 있는게 아니라 전통적으로 알고리즘기반의 여러가지 다양한 방식들에 의해서도 나타나는 이미지들 입니다.

그래서 `gabor filter` 과 같은 것들은 피로감이 있을 정도로 예전부터 보아왔다라는 것 입니다.

### Visualize Representation Space
![p11](/images/cs231n/slides/lecture9/winter1516_lecture9-11.png)

세 번째의 시각화 방법은 `Representation` 자체를 visualize 하는 것 입니다.

classification 을 수행하기 직전의 FC7. Layer 에 이미지에 대한 4096차원의 `code` 가 들어 있다고 생각할 수 있는데, 여러개의 이미지에 대한 각각의 `code`를 모아서 한번에 visualize 하는 방법입니다.

![p12](/images/cs231n/slides/lecture9/winter1516_lecture9-12.png)

대표적인 방법으로는, `t-SNE visualization` 있습니다. 여기에서는 `CNN`의 시각으로 볼 때, 유사한 것들을 가까운데로 위치시켜서 clustering 해주는 방법입니다.

오른쪽 그림은, MNIST 데이터를 `t-SNE visualization` 한 것입니다.

![p13](/images/cs231n/slides/lecture9/winter1516_lecture9-13.png)

또 다른 예시로, ImageNet 의 1000개의 class 에 대해서 CNN 의 시각으로 볼 때, 가까운 것들을 가깝게 위치시킨 것 입니다.

이것을 확대해서 보게 되면, 사람들로 구성되어 있는 부분, 시계로 구성되어있는 부분들이 모여있는 것을 확인할 수 있습니다.

### Occlusion experiments
![p15](/images/cs231n/slides/lecture9/winter1516_lecture9-15.png)

네 번째 방법으로는 Occlusion experiments 라는 것입니다.

ZFNet 을 만든 분들이 은닉, 은폐를 통해서 실험한 것으로 occluder 라는 회색부분(은페한 부분)들을 0으로 된 정사각형의 행렬로 만들어서 하나의 function 을 만든 겁니다. 즉, 이 function 에서는 occluder 들의 위치에 따라서 얼마나 이미지를 잘 분류하는지, 확률에 어떤 변화가 있는지를 마치 hit map 과 같은 방식으로 해서 보여줍니다.

occluder 를 sliding 하여 진행했을 때, 그 위치에 따른 분류 확률을 살펴본 것입니다.

예상할 수 있듯이, 파란부분에 occluder 가 위치하게 되었을때, 분류능력이 현저하게 떨어지는 것을 확인할 수 있습니다. 그리고 빨간부분에 위치하게 되면 분류능력이 상승했다고 합니다. 3번째 그림에서 사람의 얼굴을 가리게 되면 하운드로 분류할 확률이 올라갔다는 의미입니다.

### Visualize Activations

![p16](/images/cs231n/slides/lecture9/winter1516_lecture9-16.png)

이번에는 [참고영상](https://www.youtube.comwatch?v=AgkflQ4lGaM)을 통해 activation 을 시각화하는 것을 보겠습니다. 지금까지 살펴본대로 CNN 을 이용해서 이미지를 잘 분류하는 것을 학습해왔는데, 그러나 여전히 이것을 어떻게 잘 분류하느냐 즉, HOW 에 대한 부분이 여전히 black-box 로 남아있습니다. 그러다보니 이런 visualization tool 을 만들어서 보다 시각화하여 보여줌으로써 black-box 를 풀어나가는데에 도움을 주고 싶다는 내용 입니다.

참고영상에서 잠깐 언급이 되었는데, Activation 을 visualization 하는데에는 두 가지 방법이 있습니다.

1. Deconvolution-based approach
2. Optimizationi-based approach

위 두 가지 방법이 있는데, 각각에 대해서 살펴보겠습니다.

### Deconvolution based Approach

![p17](/images/cs231n/slides/lecture9/winter1516_lecture9-17.png)

이를 알아보기 앞서서 어떤 이미지가 input 으로 들어올때, 이 input 에 대한 특정 레이어에서의 하나의 뉴런의 gradient 를 계산하려면 어떻게 해야할까요?

임의의 뉴런이 위치한 레이어까지 forward pass 를 해주고 activation 을 구해준 다음에 해당 레이어에 있는 뉴런들 중 보려고 하는 graident 를 제외하고 나머지를 0으로 주어 필터링 해준다음 back propagation 을 진행해주면 됩니다.

위 처럼 진행을 하게 되면 먼저 1. 이미지를 net 에 집어넣고,

![p20](/images/cs231n/slides/lecture9/winter1516_lecture9-20.png)

레이어를 골라서 보고자 하는 gradient 를 제외하고 모두 0으로 설정하고 관심있는 neuron 만 1로 설정해줍니다.

그리고 backpropagation 을 진행합니다.

이렇게 하면 이미지에 대한 gradient 를 시각화해서 볼 수 있게 되는 것 입니다.

위 이미지를 보게 되면 blobby 한 이미지가 나오게 되는데, 그 이유는 positive 한 influence 와 negative 한 influence 가 서로 충돌하다가 서로 canceling out 을 하게 되어 애매한 이미지가 나오게 되는 것 입니다.

그래서 이것을 좀 더 선명하게 만들어주는 방법은 그냥 backpropagation 을 사용하는 것이 아니라 `Guided backpropagation` 을 사용하는 것 입니다.

`Guided backpropagation` 을 사용하게 되면 positive 한 influence 만 backpropagation 시에 반영합니다. 그렇게 하여 오른쪽 그림과 같은 선명한 이미지를 얻을 수 있습니다.

뒤에 좀 더 살펴보겠지만, `Guided backpropagation`은 다른 것은 바뀐게 없고 `ReLU` 대신에 `Modified ReLU` 를 이용해서 이런 결과를 얻어 낼 수 있는 것 입니다.

![p21](/images/cs231n/slides/lecture9/winter1516_lecture9-22.png)

a) 이 과정을 자세히 살펴보게 되면, input 이미지가 들어오고 forward pass 를 거쳐서 $f^L$ 과 같은 feature map 이 나왔다고 하겠습니다. 이때 우리가 관심을 가지고 있는 neuron 이 2 라고 한다면, 이 neuron 의 gradient 만 1로 놔두고 나머지들은 0으로 처리한 것입니다.


b) `ReLU` 의 경우를 좀 더 살펴보게 되면 input 이 들어왔을 떄, forward pass 를 진행하게 되면 0 보다 작은 빨간색 부분들을 모두 0으로 치환합니다. 그리고 backward pass 에서는 빨간색 부분 그대로 0이 될 것이고 노란색 부분에 대해서만 backward pass 가 진행되는 것을 볼 수 있습니다.

결과적으로 4군데 0인 곳을 제외한 나머지는 그대로 전달되는 것을 확인할 수 있는데, `Guided backpropagation` 에서는 `ReLU` 에 의해 0 으로 처리된 부분 외에 
`