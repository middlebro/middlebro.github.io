---
published: false
title: Lecture 7. Convolutaional Nerual Network
category: [CS231n]
use_math: true
---

> 해당 포스트는 송경석 교수님의 유튜브 강의를 정리한 내용입니다. 강의 영상은 [여기](https://youtube.com/playlist?list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5)에서 보실 수 있습니다.

저번 포스트에서 CNN 의 History 에 대해서 알아 보았습니다. 이번 포스트에서는 CNN(Convolutaional Nerual Network)를 좀 더 상세하게 살펴보겠습니다.

![p9](/images/cs231n/slides/lecture7/winter1516_lecture7-09.png)

## 1. Convolutional Neural Networks

### Convolutinal Layer

![p10](/images/cs231n/slides/lecture7/winter1516_lecture7-12.png)

기본적으로 위 그림과 같이 32 x 32 x 3 의 이미지(CFAR-10)가 width x height x depth 로 구성되어있습니다. 그래서 CNN 은 3차원으로 구성된 Volume 위에서 동작을 하는데, 각각의 레이어들은 `volumes of activations` 을 받아서 이를 다시 재생산하는 식으로 구성이 됩니다.

좀 더 자세히 보면, 5 x 5 x 3의 필터를 이미지 위에서 convolution 을 수행하기 때문에, convolution layer 라고 합니다.

Convolutional Opertaion 의 정의는 필터를 이미지 위에 Convolution 시킨다. 즉, "공간적으로 이미지 속을 slide 하면서 dot product 연산을 해 나간다" 라는 의미가 됩니다.

위 그림에서 주의깊게 보아야 하는 것은 비록 width 와 hegiht 는 32 x 32, 5 x 5로 작은 부분만 cover 하지만 depth 는 3으로 같다는 점입니다.

![p13](/images/cs231n/slides/lecture7/winter1516_lecture7-13.png)

위 그림에서 처럼 필터 $w$ 가 이미지 위를 훑어나가는 식으로 진행하게 됩니다.

필터가 5 x 5 x 3 의 이미지 조각에서 dot product 연산을 하게 되면, 75 번의 dot product 연산을 하고, 그에 대한 결과를 하나의 숫자로 return 합니다. 즉 하나의 location 당 하나의 숫자를 생상하는 것 입니다. 

이렇게 필터가 각 location 을 slide 하게 되면 다음 그림과 같이 28 x 28 x 1의 형태의  숫자들을 return 하게 됩니다.

![p14](/images/cs231n/slides/lecture7/winter1516_lecture7-14.png)

이렇게 새로 생성된 matrix 를 `activation map` 이라고 합니다.

그래서 하나의 filter 는 하나의 activation map 을 생성한다 라고 기억하면 됩니다.

![p15](/images/cs231n/slides/lecture7/winter1516_lecture7-15.png)

그런데, 여기서 녹색으로 된 두 번째 filter 를 가정해보겠습니다.

이렇게 되면, 녹색 필터가 다시한번 convolution 을 진행하면서 위에서 만든 activation map 과 같은 크기의 새로운 matrix 를 생성하게 됩니다.

![p16](/images/cs231n/slides/lecture7/winter1516_lecture7-16.png)

one filter, one activation map 이라고 했으므로, 6개의 필터를 갖고 있으면 6개의 activation map을 가지게 되는 것 입니다.

이는 또한, "32 x 32 x 3 의 이미지를 input 으로 받아 이를 어떤 activation 의 관점에서 28 x 28 x 6 이라는 새로운 형태의 이미지로 re-representaion 을 했다" 라고 생각할 수도 있습니다.

아무튼, 이렇게 생성된 결과물이 다음 convolution layer 의 input 으로 전달되는 것 입니다.

그래서 이 과정을 보게 되면 다음과 같습니다.

![p17](/images/cs231n/slides/lecture7/winter1516_lecture7-17.png)

처음 32 x 32 x 3 의 이미지를 input 으로 받아 ReLU를 통해 6개의 5 x 5 x 3 의 필터로 convolution을 하게 되면 28 x 28 x 6 이라는 activation volume 을 하나 얻게 되는 것입니다.

이 상태에서 단계를 하나 더 거쳐보겠습니다.

![p18](/images/cs231n/slides/lecture7/winter1516_lecture7-18.png)

이번에는 10개의 5 x 5 x 6 의 필터(여기에서 6이라는 값은 반드시 적용하는 volume 의 depth와 같아야 합니다.)로 convolution 하여 24 x 24 x 10 으로 계속해서 진행되는 것이 CNN 의 기본적인 형태라고 할 수 있습니다.

물론 여기에서 기억해두어야 할 점은, 우리가 궁극적으로 update 해나가야 하는 parameter는 filter의 값들이라는 것입니다. filter의 초깃값은 당연히 random 하게 시작할 것 입니다.

이렇게 학습된 filter 를 시각화하여 보게 되면 다음과 같이 됩니다.

![p19](/images/cs231n/slides/lecture7/winter1516_lecture7-19.png)

앞에서 진행한 CNN 을 통해 위와 같은 `featural hierarchy`를 얻게 됩니다.

이미지 바로 다음에 위치하는 첫번째 Convolution Layer 의 필터를 보게 되면 blob 들이 어떤 edge 나 color 로 되어 있는데, 이런 것들이 첫 번째 필터에서 볼 수 있는 것들 입니다.

그 다음 중간 단계로 진행이 되면, 앞 필터에서 나왔던 모양들이 좀 더 통합되는 것을 확인 할 수 있습니다.

깊은 레이어의 필터를 visualize 를 하게 되면 더 상위 level 의 이미지를 볼 수 있게 됩니다.

여기에서 기억해야 하는 것은 다음과 같습니다.

첫번째 필터는 input 이미지의 low weight 를 시각화한 것이고, 뒷부분의 2, 3번 필터는 low weight를 시각화 한것이 아니라 자기 바로 앞단의 filter 를 기반으로 시각화 한 것이라는 것 입니다.

![p20](/images/cs231n/slides/lecture7/winter1516_lecture7-20.png)

1959년의 Hubel & Weisel 이 상상했던 것과 굉장히 유사하게 나타난다는 것을 확인할 수 있습니다.

![p21](/images/cs231n/slides/lecture7/winter1516_lecture7-21.png)

5 x 5 filter 가 총 32 개가 있을 때, 각 filter 에 대해 하나의 activation map을 생성하게 되면, 주황색 부분이 filter 를 거쳐 높게 activation 된 것을 확인할 수 있습니다.

하얀색 부분은 activation 이 높은 지점, 검은색 부분은 activation 이 낮은 지점 으로 생각 해 볼 수 있습니다.

그래서 Convolutional 하다라고 하는 것은 filter 와 image 라는 두 개의 시그널이 Convolution 작용을 한다는 것 입니다.

![p22](/images/cs231n/slides/lecture7/winter1516_lecture7-22.png)

일반적인 CNN 은 위 그림과 같이 CONV, RELU, POOL 을 돌고 마지막에 FC Layer 로 Class의 Score 를 계산하는 식으로 구성이 됩니다.

10개의 filter 에서 10개의 activation map을 생성했고, column 내의 각 row 를 activation map 이라고 생각하면 됩니다.

![p23](/images/cs231n/slides/lecture7/winter1516_lecture7-23.png)

공간의 차원 관점으로 돌아와 좀 더 면밀히 살펴보겠습니다.

32 x 32 x 3 인 이미지에 5 x 5 x 3 의 필터를 convolution 해주어 28 x 28 x 1 의 activation map 을 얻을 때, 이 떄 28이라는 값은 어떻게 나오는 것 일까요?

![p25](/images/cs231n/slides/lecture7/winter1516_lecture7-28.png)

7 x 7 이미지에 3 x 3 의 필터를 적용시켜 본다고 해보겠습니다.

left top 에서 right top 까지의 가로방향 이동에서 5번의 이동을 하게 됩니다. 이를 세로 방향으로도 적용하게 되면 총 5 x 5 의 이동을 하게 됩니다.

이것은 stride 를 1로 했을 때의 결과입니다.

![p31](/images/cs231n/slides/lecture7/winter1516_lecture7-31.png)

만약 stride 를 2로 준다면, 2칸씩 이동하기 때문에 3 x 3의 결과를 얻게 됩니다.

![p33](/images/cs231n/slides/lecture7/winter1516_lecture7-33.png)

만약 stride 를 3으로 주게 된다면, 한번 이동한 뒤 1칸이 남게 되기 때문에, filter 가 이미지에 맞지 않게 됩니다.

![p34](/images/cs231n/slides/lecture7/winter1516_lecture7-34.png)

이를 일반화 하게 되면 위와 같이 공식화 할 수 있습니다.

$$
\text{Output size} = \frac{(N - F)}{\text{stride}} + 1
$$

![p35](/images/cs231n/slides/lecture7/winter1516_lecture7-37.png)

현실적으로는, `padding` 을 이용합니다.

zero padding 을 이용하는데, 7 x 7 의 이미지가 있을 때, 그 테두리에 0으로 pad를 대주게 됩니다.

이렇게 zero padding 을 적용하게 되면, `(7 - 3) / stride + 1`에서 `(9 - 3) / stride + 1`이 되어 7 x 7의 결과를 얻을 수 있게 됩니다.

이처럼 padding 을 사용하게 되면, input의 크기를 보존할 수 있습니다.

input 이미지가 7 x 7 이었는데, output 도 7 x 7 로 나오게 되는 것입니다.

이렇게 size 를 보존함으로써 size 에 신경쓰지 않게 해주기 때문에, 매우 편리하게 사용할 수 있습니다.

즉, convenience 가 padding 이 유용한 첫 번째 이유가 되겠습니다.

size 를 유지하기 위해서는 몇개의 padding 을 해주어야 하는지는 다음과 같이 생각할 수 있습니다.

$$
\text{P} = \frac{(F - 1)}{2}
$$

필터의 크기가 3 x 3 이면 패딩의 크기는 1, 5 x 5면 패딩은 2. 이런식으로 패딩을 설정해주면 convolution을 진행하면서도 size 를 유지 할 수 있게 됩니다.

Input 과 Output의 크기를 같게 하려면, Input의 크기가 N이라고 할 때, $N = \frac{(N + 2P - F)}{S} + 1$ 입니다.

이때, $S = 1$이므로 $P$에 대해서 식을 정리하게 되면 위 식을 얻을 수 있습니다.

이렇게 패딩을 이용해서 size 를 유지하는 것이 왜 중요할까요?

![p38](/images/cs231n/slides/lecture7/winter1516_lecture7-38.png)

앞에서의 예를 살펴보면 volume 의 크기가 32 -> 28 -> 24 로 계속해서 줄어드는 것을 볼 수 있습니다. 이렇게 계속해서 진행하다보면 0까지 가게 되면 결국 volume 자체가 shrink 해버리게 됩니다.

input 이 굉장히 거대한 신경망을 거친다고 생각을 해보겠습니다. 이러한 거대한 신경만은 수백개에서 수만개의 layer 를 거치게 될텐데, 위의 예에서는 불과 8개의 layer를 통과하면 0이 되어버리게 됩니다.

이렇게 되면 더 이상 convolution을 진행할 수 없게 됩니다.

따라서 위와 같은 문제를 해결하기 위해 padding 이 유용한 것입니다.

정리하자면, `padding` 은 `convenience`하고 `representation`이 가능하기 때문에 매우 유용하다고 할 수 있습니다.

그래서 이런 convolution layer 에서는 padding 을 이용해서 size를 보존해주되, size를 점점 줄여나가는 것(down sampling)이 의미가 있기 때문에, down sampling 은 조금 후에 살펴볼 pooling layer 에서 진행하게 됩니다.

## 요약

![p44](/images/cs231n/slides/lecture7/winter1516_lecture7-44.png)

Conv. Layer는 앞단에서 $W_1 \times H_1 \times D_1$의 Volume 을 받아서 다음단의 $W_2 \times H_2 \times D_2$의 Volume 을 생성해주는 역할을 합니다.

이 때, 항상 4가지의 하이퍼파라미터를 필요로합니다.

- 필터의 개수 $K$
- 필터의 크기 $F$
- 스트라이드 $S$
- 패딩 $P$

앞에서 본 대로, $W_2, H_2, D_2$는 다음 공식을 통해 구할 수 있었습니다.

$$
\begin{aligned}
    W_2 &= \frac{(W_1 - F + 2P)}{S} + 1 \\
    H_2 &= \frac{(H_1 - F + 2P)}{S} + 1 \\
    D_2 &= K
\end{aligned}
$$

여기서 주의해야할 점은, output의 depth $D_2$는 filter의 개수 $K$와 동일하다는 것입니다.

Weight의 총 개수는, 각각의 filter에 대해 $F \cdot F \cdot D_1$ 개의 파라미터를 갖기 때문에 이에 필터의 개수 $K$ 를 곱한 $(F \cdot F \cdot D_1) \cdot K$개가 됩니다.

여기서 $K$는 일반적으로 $2^n$의 형태를 띄게 되는데, 이는 Computation을 하는 과정에서의 편리함과 성능의 이점을 얻기 위함입니다.

마지막으로 패딩 값은 다음 식을 통해 얻을 수 있었습니다.

$$
P = \frac{(S - 1)(N - 1) + (F - 1)}{2}
$$

위의 빨간색으로 표시된 F와 S의 값들을 대입하여 P 값을 구해보면 $N \equiv 0 \mod 2$ 라는 사실을 알 수 있습니다.

그리고 $F = 1, S = 1$ 인 경우에 대해서 좀 더 자세히 살펴보겠습니다.

![p45](/images/cs231n/slides/lecture7/winter1516_lecture7-45.png)

1 x 1의 필터를 convolution 하는 것은 의미가 없을 것 같지만, 충분의 의미가 있습니다.

만약 2D를 1 x 1 필터로 Conv. 한다면 output이 input과 같아서 의미가 없겠지만, 64라는 depth를 가진 3차원에서 필터가 1 x 1 x 64의 fiber 를 거치면서 dot product 를 수행하기 때문에 충분히 의미가 있다는 것 입니다.

32 개의 필터가 있다고 한다면, 56 x 56 x 32 의 output을 얻게 됩니다.