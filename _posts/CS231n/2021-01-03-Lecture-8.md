---
published: false
title: Lecture 8. Spatial Localization and Detection
category: [CS231n]
use_math: true
---

> 해당 포스트는 송교석 교수님의 유튜브 강의를 정리한 내용입니다. 강의 영상은 [여기](https://youtube.com/playlist?list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5)에서 보실 수 있습니다.

## Localization and Detection

![p7](/images/cs231n/slides/lecture8/winter1516_lecture8-07.png)

이번 포스트에서 살펴볼 것은 Localization 과 Detection 입니다.

### Computer Vision Tasks

![p7](/images/cs231n/slides/lecture8/winter1516_lecture8-08.png)

우선, 유사한 개념들의 차이점을 정리해보고 들어가도록 하겠습니다.

Classification 은 이미지가 들어오면 이 이미지가 어떠한 이미지인지, 예를 들어 위의 그림과 같이 CAT 이라고 labeling 해주는 것 입니다.

Classification + Localization 은 분류와 함께, Localization 을 진행하는 것인데, CAT 이 이미지의 어디에 위치해 있는지를 Boxing 해주는 것을 localization 이라고 합니다.

다음으로, Detection 이라는 것은 하나의 object 를 boxing 해주는 localization 과는 다르게 여러개의 Object 들을 모두 찾아내는 것을 Object Detection 이 되겠습니다.

마지막으로 Segmentation 은 위 그림과 같이 고양이, 오리, 개를 형상대로 테두리를 따 주는 것을 말합니다.

그래서 이번 포스트에서는 Localization 과 Detection 에 대해 다뤄보고, Segmentation 은 후에 Lecture 13 에서 다뤄보도록 하겠습니다.

## Localization

![p7](/images/cs231n/slides/lecture8/winter1516_lecture8-10.png)

Classification 은 C 클래스가 있을 떄 input 으로 이미지를 받아서 output 으로 Class label 을 줍니다. 그리고 이를 평가하는 지표는 Accuracy(정확도)가 됩니다. 위 그림에서 처럼 이미지가 들어왔을 떄 고양이다 라고 분류를 하는 식으로 동작합니다.

Localization 은 이미지가 들어오면 결과로 Label 이 아닌 Box를 리턴합니다. 예를 들어 left top 에서 시작하는 (x, y) 좌표와 width, height 를 주게 되는 것 입니다. 그리고 평가 지표는 IoU(Intersaction over Union). 즉, 겹치는 부분이 몇 퍼센트인지 가 됩니다.

그리고 Classification 과 Localization 을 같이 진행하게 되면, Label 과 (x, y, w, h) 를 같이 얻게 되는 것 입니다.

![p7](/images/cs231n/slides/lecture8/winter1516_lecture8-11.png)

이전 포스트들에서 계속 언급했던 ImageNet 에는 Classification 대회만 있는 것이 아니라 여러가지 대회가 있는데, 그 중 하나가 Classification 과 Localization 을 결합한 것이 되겠습니다.

여기서도 마찬가지로 1,000 개의 Class 들이 있고, 각 이미지들에는 1개의 Class 와 최소 1개의 bounding box 가 있습니다. 그리고 Classification 에서 와 같이 top 5 error 를 계산했던 것 처럼, 5개의 후보를 추출하여 최소한 1개의 Class 를 맞추고, IoU 가 0.5 이상이 되면 맞춘걸로 간주합다고 합니다.

### Idea 1. Localization as Regression

![p7](/images/cs231n/slides/lecture8/winter1516_lecture8-12.png)

Localization 을 하는 방법에는 크게 2가지가 있습니다. 그 중 첫 번째 방법은 Localization as Regression 입니다. 즉, Localization 을 Regression 이라고 간주하는 것인데, 이 방법은 나름 매우 강력합니다.

1개를 localize 하거나 $k$ 개를 localize 할 때, Image Detection 을 고집하지 않고 이 방법을 사용해도 된다는 의미입니다.

방법은 다음과 같습니다.

- 이미지를 input 으로 받아 신경망에 넣어줍니다.
- output 으로 4개의 숫자로 구성된 box 의 좌표를 얻습니다.
- 이를 실제 correct box 좌표와 비교를 하여 L2 Distance 를 활용한 Loss 를 구하게 됩니다.
- 이렇게 구한 Loss 를 Backpropagation 때 학습하여 최적화합니다.

단계별로 보면 다음과 같습니다.

![p7](/images/cs231n/slides/lecture8/winter1516_lecture8-13.png)

첫 번째 단계에서는 Classification model 을 학습시킵니다.

![p7](/images/cs231n/slides/lecture8/winter1516_lecture8-14.png)

두 번째 단계에서는 지금까지 해왔던 `Classification head` 에 `Regression head` 를 추가 해줍니다.

그래서 `Regression head` 에서는 결과물이 박스의 좌표가 되도록 합니다.

![p15](/images/cs231n/slides/lecture8/winter1516_lecture8-15.png)

세 번째 단계에서는 방금 앞에서 추가했던 `Regression head` 부분만 학습을 진행합니다.

![p16](/images/cs231n/slides/lecture8/winter1516_lecture8-16.png)

그리고 마지막 단계에서는 `Classification head` 와 `Regression head` 모두를 이용해서 결과물을 산출해냅니다.

이처럼 간단하게 구성이 됩니다.

![p17](/images/cs231n/slides/lecture8/winter1516_lecture8-17.png)

그런데, `Regression head` 부분에는 `Per-class` 와 `Class agnostic` 이라는 2 가지 방법이 있습니다.

쉽게 말하면, `Per-class` 는 어떤 Class 에 특화된, Class Specific 한 방법이고, `Class agnostic` 이라는 것은 각각의 Class 와 무관하게, 범용적인 접근 방법이라고 할 수 있습니다.

`class agnostic` 은 특정 class 에 특화되지 않기 떄문에, 하나의 box 만을 결과물로 도출하게 됩니다.

반면에, `per-class` 즉, `class specific` 은 각 class 당 하나의 box. 즉, 4개의 숫자가 각 class 별로 결과를 도출하게 됩니다.

이 두가지 방법은 loss 를 계산하는 방법 외에는 별 차이가 없는 굉장히 유사한 방법입니다. 다만, loss 계산에서 `class specific` 한 방법은 Ground-truth 의 좌표만 이용한다는 차이만 있습니다.

![p18](/images/cs231n/slides/lecture8/winter1516_lecture8-18.png)

그렇다면, `Regression head`를 어디에 붙여야하는지에 대해서 보겠습니다.

이것도 두 가지 방법이 있는데, 두 가지 방법 모두 통합니다.

첫 번째로, 마지막 CONV. Layer 뒤에 붙여주는 방법이 있습니다. Overfeat 이나 VGG 같은 경우 이렇게 합니다.

아니면, FC. Layer 뒤에 붙여주는 방법이 있습니다. DeepPose 나 R-CNN 같은 경우가 이런 경우인데, 어떤 경우든 잘 동작합니다.

![p19](/images/cs231n/slides/lecture8/winter1516_lecture8-19.png)

참고로 여러개 Object 의 Localizing 도 잘 동작합니다.

정해진 $K$ 개의 Object 를 찾아내는 것은 Regression 만으로도 잘 동작하기 때문에, 굳이 모든 것을 찾아내야하는 경우가 아니고 정해진 개수만 찾아내면 되는 경우라면 Detection 을 사용하지 않고, Regression 만을 이용해서 쉽게 구현이 가능하다는 것 입니다.

이러한 예로 사람의 자세를 측정하는 것이 있습니다.

![p20](/images/cs231n/slides/lecture8/winter1516_lecture8-20.png)

사람의 관절 수는 정해져 있기 때문에, Regression 을 통해 쉽게 구현이 가능합니다.

![p21](/images/cs231n/slides/lecture8/winter1516_lecture8-21.png)

정리하자면, Regression 을 통해서 Localization 을 하는 것은 매우 Simple 하고, 나름 강력하기 때문에 여러 사례에 충분히 응용하기 쉽습니다. 다만, ImageNet Competition 과 같은데에서 수상이 목적이라면, 좀 더 복잡한 방법을 사용해야 할 것입니다. 바로 다음으로 살펴볼 `sliding window` 가 그것입니다.

### Idea 2. Sliding Window

![p22](/images/cs231n/slides/lecture8/winter1516_lecture8-22.png)

지금부터, Localization 을 하는 두 번째 방법인 `Sliding Window` 에 대해서 알아보겠습니다.

기본적으로 앞의 `Regression` 방법과 동일하게, `Classification head`와 `Regression head` 두 개로 분류해서 진행을 합니다만, 이미지를 한번만 돌리지 않고 이미지 여러 군데를 돌려 합쳐주는 기법입니다.

그리고 또한, 편의성을 위해 FC. Layer 를 CONV. Layer 로 변환해주어 연산을 진행하게 됩니다.

`Sliding Window` 의 대표적인 것이 overfeat 이므로, overfeat 에 대해서 알아보도록 하겠습니다.

![p23](/images/cs231n/slides/lecture8/winter1516_lecture8-23.png)

`Overfeat` 은 2013년 ImageNet Localization Challenage 에서 5승을 한 모델로, 기본적으로는 AlexNet 을 응용한 것 입니다.

Classification head 와 Regression head 두 개로 구성이 되는데, sliging window 에서의 차이점은 다음과 같습니다.

![p24](/images/cs231n/slides/lecture8/winter1516_lecture8-25.png)

input 이미지보다 좀 더 큰 이미지로 진행합니다.

가운데 이미지에서 검은색 box 가 sliding window 가 됩니다. 이 sliding window 가 위치한 left top 에서 regression head 로 빨간색의 bounding box 를 만들게 되고, classification head 에 의해서 고양이로 분류하는 score 를 계산해주게 됩니다. 오른쪽 그림이 left top 에서의 score 입니다.

이렇게 right bottom 까지 진행을 하게 되면, 다음과 같이 됩니다.

![p22](/images/cs231n/slides/lecture8/winter1516_lecture8-28.png)

결과적으로 얻게되는 것은, 아래 그림과 같이 4개의 bouding box 와 4개의 score 가 됩니다.

![p29](/images/cs231n/slides/lecture8/winter1516_lecture8-29.png)

여기에서 알고리즘을 상세하게 설명하지는 않지만, 다음과 같이 합칩니다.

![p30](/images/cs231n/slides/lecture8/winter1516_lecture8-30.png)

이렇게 단일 bouding box 와 단일 score 를 얻는 것이 최종적인 결과가 되겠습니다.

이 예제에서는 간단하게, 슬라이딩 윈도우를 4개로 구성하여 진행했는데, 실제로는 훨씬 더 많은 슬라이딩 윈도우를 사용합니다.

![p31](/images/cs231n/slides/lecture8/winter1516_lecture8-31.png)

위 그림을 보시면, 수십에서 수백개의 슬라이딩 윈도우를 사용하고 결과적으로 스코어 맵을 작성한 것을 볼 수 있습니다.

최종 결과를 보게 되면, 이미지가 곰인 것을 확인 할 수 있는데, score map 을 보게 되면 곰이 있는 부분의 socre 가 높게 표시되는 것을 확인할 수 있습니다.

box 또한 곰 쪽으로 몰려 있는 것을 확인할 수 있습니다.

결과적으로는, 곰을 bounding box 가 정확하게 포착한 것도 확인할 수 있습니다.

그런데 이렇게 수 많은 슬라이딩 윈도우를 사용하게 되면, 각각의 슬라이딩 윈도우에 대해서 network 를 돌려야 하기 때문에 연산비용이 많이 들어가게 됩니다.

![p32](/images/cs231n/slides/lecture8/winter1516_lecture8-32.png)

연산비용이 많이 들기 때문에, 뒷단에서 FC. Layer 를 CONV. Layer 로 바꿔준다는 것 입니다.

![p33](/images/cs231n/slides/lecture8/winter1516_lecture8-33.png)

이렇게 CONV. Layer 로 바꿔주어 연산을 더 효율적으로 진행한다는 것 입니다.

기본적으로 앞에서의 FC. Layer 는 4096개로 구성이 되어있었습니다. 이를 vector 로 생각하는 것이 아닌, 또 하나의 Convolutional feature map 으로 생각한다는 것 입니다.

그래서 이를 transpose 해주고, `1 x 1` 의 차원을 추가해줌으로써 이렇게 CONV. Layer 로 구성하는 것 입니다.

이처럼 FC. Layer 를 CONV. Layer 로 만들어줌으로써, CONV, POOL, element-wise operation으로 만 네트워크를 구성할 수 있는 것 입니다.

![p34](/images/cs231n/slides/lecture8/winter1516_lecture8-34.png)

트레이닝 시에는, `14 x 14`의 이미지를 받아서 `5 x 5`의 필터로 Convolution 을 해주게 되면, `(14 - 5)/1 + 1 = 10`이므로 `10 x 10`이 되고, 이것을 `2 x 2` 필터로 Poolling 해주면 `5 x 5`의 결과를 얻게 됩니다.

여기서부터 우측을 모두 convolution 으로 바꾸었기 때문에, `(5 - 5)/1 + 1 = 1`로 `1 x 1` 크기로 변환되는 것을 볼 수 있습니다.

테스트 때는, 좀 더 큰 이미지인 `16 x 16`의 이미지로 진행하여 `2 x 2` 크기의 결과를 얻게 됩니다.

![p35](/images/cs231n/slides/lecture8/winter1516_lecture8-35.png)

ImageNet 에서의 Classification + Localization 성적을 보게되면, 2012년에는 AlexNet, 2013년에는 지금까지 본 Overfeat, 2014년에는 VGG 가 우승을 한 것을 볼 수 있습니다.

2015년의 ResNet 은 152개의 layer 로 구성이 되어 있으면서, 깊이도 깊어졌지만 기본적으로는 localize 하는 방법 자체를 바꿨습니다.

RPN(Regional Proposal Network)이라는 것을 이용하여, 기존과는 비교가 안되는 정확도로 localization을 수행한 것을 볼 수 있습니다.

![p36](/images/cs231n/slides/lecture8/winter1516_lecture8-36.png)

지금까지 Classification + Localization 에 대해서 살펴보았습니다.

이제부터는 Object Detection. 즉, 한 이미지 내에서 불특정 여러개의 이미지를 인식하는 것에 대해서 학습해보겠습니다.

![p37](/images/cs231n/slides/lecture8/winter1516_lecture8-37.png)

## Object Detection

![p38](/images/cs231n/slides/lecture8/winter1516_lecture8-38.png)

앞에서, Localization을 볼 때, `Regression`이 잘 동작했습니다. 그래서 `Regression`을 `Detection`에서도 활용해보면 어떻겠는가라는 것이 첫 번째 아이디어가 됩니다.

예를 들어 위의 이미지의 경우, 고양이가 2마리, 오리와 개가 각 한마리 씩 있습니다.

이 이미지를 가지고 `Detection`을 진행하게 되면  `(x, y, w, h)` 의 16개의 number 가 도출이 되게 됩니다.

![p39](/images/cs231n/slides/lecture8/winter1516_lecture8-39.png)

만약, 위 그림과 같이 고양이와 개가 한마리씩 있는 이미지라면, 총 8개의 number 가 도출이 되게 됩니다.

![p40](/images/cs231n/slides/lecture8/winter1516_lecture8-40.png)

마지막으로, 이런 이미지라면 수십개의 number 가 도출되게 될 것입니다.

여기서 확인할 수 있는 것은, 이미지에 따라서 Object 의 개수가 달라지기 때문에, output 의 개수가 달라진 다는 것 입니다.

따라서 `Regression`을 적용하기에는 적당하지 않습니다.

그럼에도 불구하고, 나중에 보게 될 `YOLO(You Only Look Once)` 라는 모델은 `Regression`을 사용해서 `Detection`을 진행하게 됩니다만, 일반적으로는 적당하지 않다고 생각하면 됩니다.

![p41](/images/cs231n/slides/lecture8/winter1516_lecture8-41.png)

아무튼, `Regression`은 `Detection`에 적합하지 않기 때문에, `Classification`으로 간주하여 진행해보자는 것입니다.
